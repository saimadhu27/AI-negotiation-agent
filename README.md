# ðŸ§  Real-Time Multi-Agent Voice AI System

A **real-time, multi-agent conversational pipeline** that enables **low-latency, bidirectional audio dialogue** between users and AI agents via **Twilio Voice**, **WebSockets**, and **streaming LLMs**.  
The system demonstrates how to build **autonomous, speech-driven agents** capable of interacting naturally over phone calls â€” all in **under 500 ms round-trip latency**.

---

## ðŸš€ Features

- ðŸŽ™ï¸ **Real-Time Streaming** â€” Bidirectional audio handled via WebSockets with sub-500 ms latency.  
- ðŸ¤– **Multi-Agent Orchestration** â€” Modular design allows multiple AI agents (e.g., assistant, summarizer, emotion detector) to cooperate in dialogue.  
- â˜ï¸ **LLM-Powered Reasoning** â€” Integrates streaming LLMs for dynamic, contextual responses.  
- â˜Žï¸ **Twilio Voice Integration** â€” Seamlessly connects phone calls to your AI agents.  
- ðŸ§© **Server-Client Architecture** â€” Built with **FastAPI** and **Uvicorn**, supporting scalable asynchronous I/O.  
- ðŸ”Š **Speech â†” Text Conversion** â€” Uses Whisper for transcription and real-time voice synthesis for responses.  
- ðŸ§± **Modular & Extensible** â€” Easily plug in different LLMs, voice models, or downstream reasoning agents.  

---

## ðŸ—ï¸ System Architecture

```
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      HTTP POST       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Twilio Voice â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚ FastAPI Server     â”‚
 â”‚  (Phone Call)â”‚                      â”‚  /outgoing-call    â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                      â”‚
        â–¼                                      â–¼
  WebSocket Media Stream           â†”      WebSocket LLM Stream
 (Audio in/out via Twilio)                  (Text/Audio from OpenAI)
        â”‚                                      â”‚
        â–¼                                      â–¼
  Whisper ASR  â”€â”€â”€â”€â”€â”€â”€â–¶  Streaming LLM  â”€â”€â”€â”€â”€â”€â”€â–¶  TTS Audio Output
```

---

## âš™ï¸ Tech Stack

| Component | Technology |
|------------|-------------|
| **Backend Framework** | FastAPI + Uvicorn |
| **Telephony** | Twilio Voice (Programmable Voice, Media Streams) |
| **Real-time Transport** | WebSockets |
| **Language Model** | Streaming LLM API (OpenAI Realtime or equivalent) |
| **Speech Recognition** | Whisper (g711_ulaw format) |
| **Audio Synthesis** | Alloy / Voice model |
| **Runtime** | Python 3.11 |
| **Infra Ready** | Docker + AWS EC2 (or local) |

---

## ðŸ§© Folder Structure

```
AI-agent/
â”œâ”€â”€ voice_server.py         # Main FastAPI app handling Twilio + WS
â”œâ”€â”€ test_ws_connect.py      # WebSocket connectivity test script
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ ...
```

---

## ðŸ§ª Local Development

### 1. Clone and install dependencies
```bash
git clone https://github.com/yourusername/AI-agent.git
cd AI-agent
python -m venv vagents
source vagents/bin/activate
pip install -r requirements.txt
```

### 2. Run the FastAPI server
```bash
python -m uvicorn voice_server:app --reload
```

The server will start at:
```
http://127.0.0.1:8000
```

### 3. Test WebSocket connection
```bash
python test_ws_connect.py
```
If you see `Connected ok`, your agent server is ready to handle Twilio streams.

---

## â˜ï¸ Deployment

- **Dockerize** the FastAPI app for reproducibility.
- Deploy on **AWS EC2**, **Render**, or **Vercel** with a public HTTPS endpoint.
- Update your **Twilio Voice Webhook URL** to point to:
  ```
  https://your-domain.com/outgoing-call-twiml
  ```

---

## ðŸ“ž Example Use Case

This system can power:
- Autonomous **customer service agents**  
- **Scheduling assistants** that converse naturally  
- **Information hotlines** for businesses or nonprofits  
- Multi-agent **dialogue systems** (agent-to-agent collaboration)  

---

## ðŸ§  Future Enhancements

- ðŸ” Add memory & context chaining between turns  
- ðŸ§© Integrate retrieval (RAG) for domain-specific knowledge  
- ðŸ’¬ Enable multi-language voice support  
- ðŸ•µï¸ Add emotion detection & dynamic response modulation  

---

## ðŸªª Author

**Madhuri [Your Last Name]**  
ðŸ’¼ *AI Engineer | Applied ML & Conversational Systems*  
ðŸ”— [LinkedIn](#) â€¢ [GitHub](#)

---

## â­ï¸ Highlight for Resume

> **â€œDeveloped a real-time multi-agent AI voice pipeline leveraging WebSockets, Twilio, and streaming LLMs to enable low-latency (<500 ms) bidirectional conversations, demonstrating scalable autonomous dialogue systems for customer-facing applications.â€**
